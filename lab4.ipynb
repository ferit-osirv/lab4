{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferit-osirv/lab4/blob/main/lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8vtuqXEBP1j"
      },
      "source": [
        "# Lab 4 - Detekcija značajki (rubova, kutova, Hough transformacija)\n",
        "\n",
        "Ove laboratorijske vježbe se rješavaju u Google Colabu i spremaju na GitHub repozitorij koji je povezan na GitHub Classroom.\n",
        "\n",
        "## Kako riješiti zadatke?\n",
        "\n",
        "1. Prihvatite zadatak putem Google Classroom linka koji ćete dobiti. Google Classroom će kreirati repozitorij na vašem računu.\n",
        "2. Uđite u novokreiran repozitorij na vašem računu u kliknite na **.ipynb** datoteku, zatim kliknite **Open in Colab**.\n",
        "3. Zadatke rješavate u Google Colabu.\n",
        "\n",
        "## Kako spremiti (predati) zadatke?\n",
        "\n",
        "1. Unutar **Google Colaba** kliknite na **Open settings** kotačić u gornjem desnom kutu.\n",
        "2. Kliknite na **GitHub** tab i odaberite kvačicu za **Access private repositories and organizations**.\n",
        "3. Otvorit će se novi prozor da dodate pristup GitHubu. Kod **ferit-osirv** kliknite **Grant**.  \n",
        "4. Spremite i izađite iz postavki.\n",
        "\n",
        "\n",
        "5. Kliknite na **File > Save a copy in GitHub**.\n",
        "6. Odaberite kreiran repozitorij labosa **koji uključuje vaše ime**.\n",
        "\n",
        "> *Napomena:* Korake 1-4 morate napraviti samo prvi put."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feUPz7IDCbDx"
      },
      "source": [
        "## Kopiranje datoteka iz GitHub repozitorija\n",
        "\n",
        "Za izradu vježbi bit će vam potrebne slike i druge datoteke koje će se nalaziti u GitHub repozitoriju vježbe. Ovakva komanda će biti dostupna u notebooku svake vježbe. Ona će kopirati datoteke s GitHuba u Google Colab okruženje.\n",
        "\n",
        "**Ovu komandu je potrebno pokrenuti prije nego što krenete raditi svaku vježbu.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpP_i0KgCefb",
        "outputId": "e08a0979-cb3c-41f4-be61-07957597ae31"
      },
      "outputs": [],
      "source": [
        "!rm -rf clone && git clone https://github.com/ferit-osirv/lab4 clone && cp -a clone/. ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIPg8Vf9Cr8D"
      },
      "source": [
        "**Google Colab će povremeno obrisati sve datoteke.** Tako da će možda biti potrebno ponovno pokrenuti ovu komandu između dvije sesije. Ako dobivate greške da datoteke ne postoje, probajte ponovno pokrenuti gornju komandu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "EXS_YJC2WsWD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>5.1. Edge Detection</h2>\n",
        "\n",
        "When talking about images, the edge can be defined as a boundary between two regions with relatively distinct gray level properties.\n",
        "Edges are pixels where the brightness function changes abruptly.\n",
        "Edge detectors are a collection of very important local image preprocessing methods used to locate (sharpen) changes in the intensity function.\n",
        "Different edge detection methods include Canny, Sobel, Roberts, SUSAN, Prewitt, and Deriche.\n",
        "\n",
        "<h3>5.1.1. Edge Detection with Canny Edge descriptor</h3>\n",
        "\n",
        "Canny Edge Detection is a popular edge detection algorithm. \n",
        "This is a multi-step algorithm, so its successful performance, depends on few steps: \n",
        "\n",
        "<ul>\n",
        "  <li><b>Preprocessing (noise reduction)</b></li>\n",
        "  Since all edge detection results are easily affected by image noise, it is essential to filter out the noise to prevent false detection caused by noise. \n",
        "  To smooth the image, we will use a Gaussian filter. \n",
        "  This step will slightly smooth the image to reduce the effects of obvious noise on the edge detector.\n",
        "  The equation for a Gaussian filter with a kernel of size (2k+1) x (2k+1) is given with: \n",
        "\n",
        "![gauss](https://wikimedia.org/api/rest_v1/media/math/render/svg/4a36d7f727beeaff58352d671bb41a3aca9f44d6)\n",
        "  \n",
        "  As seen from the above formula, important parameters for the Gaussian filter are:\n",
        "  <ul>\n",
        "    <li>size of the kernel (mostly 5x5 kernel is used)</li>\n",
        "    <li>and standard deviation sigma </li>\n",
        "  </ul>\n",
        "  \n",
        "   <p>\n",
        "  <li><b>Finding intensity gradient of the image</b></li>\n",
        "  An edge in an image may point in a variety of directions, so the Canny algorithm uses filters to detect horizontal, vertical and diagonal edges in the blurred image. \n",
        "  The edge detection operator (such as Roberts, Prewitt, or Sobel) returns a value for the first derivative in the horizontal direction (Gx) and the vertical direction (Gy). \n",
        "  In other words, <i>the magnitude</i> of the gradient at a point in the image determines if it possibly lies on the edge or not. A high gradient magnitude means the colors are changing rapidly which implies the existence of an edge while a low gradient implies that edge is not present. \n",
        "  The <i>direction</i> of the gradient shows how the edge is oriented.\n",
        "  To calculate these, following formulas are used: \n",
        "\n",
        "![canny-edge-1](http://latex.codecogs.com/gif.latex?Edge%20Gradient%20%28G%29%20%3D%20%5Csqrt%7BG_x%5E2&amp;plus;G_y%5E2%7D)\n",
        "![canny-edge-2](http://latex.codecogs.com/gif.latex?Angle%20%28%5Ctheta%29%20%3D%20%5Ctan%5E%7B-1%7D%5Cfrac%7BG_y%7D%7BG_x%7D)\n",
        "\n",
        "  Once we have the gradient magnitudes and orientations, we can get started with the actual edge detection.\n",
        " \n",
        " </p>\n",
        "\n",
        " <p>\n",
        "  <li><b>Applying non-maximum suppression to get rid of spurious response to the edge detection</b></li>\n",
        "\n",
        "  After gradient magnitude and direction are obtained, a full scan of the image is done to remove any unwanted pixels which may not constitute the edge.\n",
        "  Therefore, edge thining technique known as non-maximum suppression is applied to find all those unwanted pixels. \n",
        "  For this, at every pixel, the pixel is checked if it is a local maximum in its neighborhood in the direction of the gradient. Check the image below: \n",
        "\n",
        "![non-maximum](https://docs.opencv.org/3.1.0/nms.jpg)\n",
        "  <br>\n",
        "  Point A is on the edge ( in the vertical direction). Gradient direction is normal to the edge. Point B and C are in gradient directions. \n",
        "  So point A is checked with point B and C to see if it forms a local maximum. If so, it is considered for the next stage, otherwise, it is suppressed ( put to zero).\n",
        "  In short, the result you get is a binary image with \"thin edges\".\n",
        "</p>\n",
        "\n",
        "  <li><b>Track edge by hysteresis </li></b>\n",
        "  Finalize the detection of edges by suppressing all the other edges that are weak and not connected to strong edges.\n",
        "  This stage decides which are all edges are really edges and which are not. For this, we need two threshold values, minVal, and maxVal. \n",
        "  Any edges with intensity gradient more than maxVal are sure to be edges and those below minVal are sure to be non-edges, so discarded. \n",
        "  Those who lie between these two thresholds are classified edges or non-edges based on their connectivity. \n",
        "  If they are connected to \"sure-edge\" pixels, they are considered to be part of edges. Otherwise, they are also discarded. See the image below:\n",
        "\n",
        "![non-maximum](https://docs.opencv.org/3.1.0/hysteresis.jpg)\n",
        "\n",
        " <p>\n",
        "    The edge A is above the maxVal, so considered as \"sure-edge\". Although edge C is below maxVal, it is connected to edge A, so that also considered as valid edge and we get that full curve. \n",
        "    But edge B, although it is above minVal and is in the same region as that of edge C, it is not connected to any \"sure-edge\", so that is discarded. \n",
        "    So it is very important that we have to select minVal and maxVal accordingly to get the correct result. \n",
        "    This stage also removes small pixels noises on the assumption that edges are long lines. So what we finally get is strong edges in the image.\n",
        " </p>\n",
        "  \n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OpenCV implementation of Canny edge detector:\n",
        "\n",
        "```\n",
        "Function : cv2.Canny(blurred image,lower threshold,upper threshold)\n",
        "Parameters are as follows :\n",
        "1. blurred image : input image blurred with Gaussian 5 by 5 kernel\n",
        "2. lower threshold : first threshold for the hysteresis procedure\n",
        "3. upper threshold : second threshold for the hysteresis procedure\n",
        "```\n",
        "More information can be found at:  <a href=\"https://docs.opencv.org/3.0-beta/modules/imgproc/doc/feature_detection.html?highlight=cv2.canny#cv2.Canny\">OpenCV cv2.Canny documentation</a> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Zadatak 1\n",
        "\n",
        "Isprobajte Canny edge detektor na proizvojnoj slici unutar direktorija `slike`. **Učitajte sliku kao grayscale sliku.** Također, prije obavljanja Canny edge detekcije sliku zamutite **Gaussian blurom**. (Prisjetite se prošlih vježbi.) Prikažite izvornu sliku i sliku detektiranih rubova. Odokativno odredite vrijednosti parametara lower i upper threshold kako bi dobili jasne rubove bez previše viška rubova. Dobre početne vrijednosti su između 100 i 200."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you could observe, the common problem here is in determining these lower and upper thresholds. So, what is the optimal value for the thresholds?\n",
        "This question is especially important when you are processing multiple images with different contents captured under varying lighting conditions.  \n",
        "A little trick that relies on basic statistics can help you automatically determ these values, removing the manual tuning of the thresholds for Canny edge detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>5.2. Hough Transformation for Lines</h3>\n",
        "\n",
        "When images are to be used in different areas of image analysis such as object recognition, it is important to reduce the amount of data in the image while preserving the important,\n",
        "characteristic, structural information. Edge detection makes it possible to reduce the amount of data in an image considerably. However the output from an edge detector is still a image\n",
        "described by it’s pixels. If lines, ellipses and so forth could be defined by their characteristic equations, the amount of data would be reduced even more. \n",
        "The Hough transform was originally developed to recognize lines and has later been generalized to cover arbitrary shapes. \n",
        "\n",
        "<ul>\n",
        "<li> <b>Representation of Lines in the Hough Space</b> </li>\n",
        "\n",
        "Lines can be represented uniquely by with parameters a and b and following equation: \n",
        "\n",
        "![line-1](https://latex.codecogs.com/gif.latex?y%3Da%5Ccdot%20x%20&plus;b)\n",
        "\n",
        "Above equation is not able to represent vertical lines. Therefore, the Hough transform uses the following equation: <br>\n",
        "\n",
        "![line-2](https://latex.codecogs.com/gif.latex?r%20%3D%20x%20%5Ccdot%20%5Ccos%20%5CTheta%20&plus;%20y%5Ccdot%20%5Csin%20%5CTheta)\n",
        "\n",
        "To obtain similar equation to the first one, this can be rewritten as: \n",
        "\n",
        "![line-3](https://latex.codecogs.com/gif.latex?y%20%3D%20-%20%5Cfrac%7B%5Ccos%20%5CTheta%20%7D%7B%5Csin%20%5CTheta%20%7D%20%5Ccdot%20x%20&plus;%20%5Cfrac%7Br%7D%7B%5CTheta%20%7D)\n",
        "\n",
        "The parameters ![line-1](https://latex.codecogs.com/gif.latex?%5Ctheta) and r is the angle of the line and the distance from the line to the origin, respectively. \n",
        "All lines can be represented in this form when  <img src=\"https://i.ibb.co/4Sq4DkD/formula1.png\" alt=\"hough1\" border=\"0\"></a>.\n",
        "To sum up, the Hough space for lines has these two dimensions: ![line-1](https://latex.codecogs.com/gif.latex?%5Ctheta) and r and a line is represented\n",
        "by a single point, corresponding to a unique set of parameters ![line-1](https://latex.codecogs.com/gif.latex?%28%5Ctheta%20_%7B0%7D%2Cr_%7B0%7D%29) . \n",
        "The line-to-point mapping is illustrated in the following image: \n",
        "<p align=\"center\">\n",
        "<img src=\"https://i.ibb.co/gJ9C8Jy/hough1.png\" alt=\"hough1\" border=\"0\"></a><br /><br />\n",
        "</p>\n",
        "\n",
        "<li> <b>Mapping of edge points to the Hough space</b> </li>\n",
        "\n",
        "An important concept for the Hough transform is the mapping of single points. The idea is, that a point is mapped to all lines, that can pass through that point.\n",
        "This yields a sine-like line in the Hough space.  This principle is illustrated for a point ![formula](https://latex.codecogs.com/gif.latex?p_%7B0%7D%3D%20%2840%2C30%29)as shown in following figures: \n",
        "<p align=\"center\">\n",
        "<img src=\"https://i.ibb.co/GVRDyJs/houghspace.png\" alt=\"houghspace\" border=\"0\">\n",
        "</p>\n",
        "On the left image transformation of a single point to a line in the Hough space is shown while on the right image \n",
        "the Hough space line representation through all possible lines through the point is shown. \n",
        "\n",
        "<li><b>The Hough Space Accumulator<b/></li>\n",
        "To determine the areas where most Hough space lines intersect, an accumulator covering the Hough space is used. When an edge point is transformed, bins in the accumulator is incremented\n",
        "for all lines that could pass through that point. The resolution of the accumulator determines the precision with which lines can be detected. \n",
        "In general, the number of dimensions of the accumulator corresponds to the number of unknown parameters in the Hough transform problem. Thus, for ellipses a 5-dimensional space is required\n",
        "(the coordinates of its center, the length of its major and minor axis, and its angle). For lines 2 dimensions suffice (r and θ). This is why it is possible to visualize the content of the ac\n",
        "cumulator.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To sum up, the algorithm for detecting straight lines can be divided to the following steps: \n",
        "<ul>\n",
        "<li> Edge detection, e.g. using the Canny edge detector </li>\n",
        "<li> Mapping of edge points to the Hough space and storage in an accumulator </li>\n",
        "<li> Interpretation of the accumulator to yield lines of infinite length. The interpretation isdone by thresholding and possibly other constraints. </li>\n",
        "<li> Conversion of infinite lines to finite lines. </li>\n",
        "</ul>\n",
        "\n",
        "More information about Hough Transformation for lines can be found at:  <a href=\"href> https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_houghlines/py_houghlines.html\">OpenCV Hough Transform documentation</a> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OpenCV implementation of Hough Transform for lines can be found in: \n",
        "\n",
        "```\n",
        "Function : cv2.HoughLines(image with edges,rho,theta,threshold, array,srn,stn)\n",
        "Parameters are as follows :\n",
        "1. image with edges : input image with found edges\n",
        "2. rho : distance resolution of the accumulator in pixels\n",
        "3. theta : angle resolution of the accumulator in radians\n",
        "4. threshold: accumulator threshold parameter. only those lines are returned that get enough votes \n",
        "5. array: return an empty array with shape and type of input for storing result\n",
        "6. srn: for the multi-scale Hough transform, if 0 standard Hough transform is used\n",
        "7. stn: for the multi-scale Hough transform, if 0 standard Hough transform is used\n",
        "```\n",
        "More information can be found at:  <a href=\"https://docs.opencv.org/3.0-beta/modules/imgproc/doc/feature_detection.html?highlight=cv2.hough#cv2.HoughLines\">OpenCV cv2.HoughLines documentation</a> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Zadatak 2\n",
        "\n",
        "Na slici `crossword.jpg` obavite Hough transfromaciju. Obzirom da je ulaz u `HoughLines` funkciju slika s detektiranim rubovima, prvo morate napravity Canny edge detection kao u prvom zadatatku, uključujući i blur. Na slici rubova zatim napravite Hough transformaciju. Nakon obavljene transformacije pozotive funkciju `draw_lines` koja će na **izvornoj slici** nacrtati pronađene linije. Prikažite rezultirajuću sliku. Primjer poziva:\n",
        "\n",
        "`lines = cv2.HoughLines(edges, 1, math.pi/90, 200, np.array([]), 0, 0)`\n",
        "\n",
        "Ovo su dobre početne vrijednosti parametera. Parametar `threshold` koji je jednak 200 u gornjem pozivu prilagodite slici tako da dobijete linije križaljke."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def draw_lines(img, lines):\n",
        "  a,b,c = lines.shape\n",
        "  for i in range(a):\n",
        "      rho = lines[i][0][0]\n",
        "      theta = lines[i][0][1]\n",
        "      a = math.cos(theta)\n",
        "      b = math.sin(theta)\n",
        "      x0, y0 = a*rho, b*rho\n",
        "      pt1 = ( int(x0+1000*(-b)), int(y0+1000*(a)) )\n",
        "      pt2 = ( int(x0-1000*(-b)), int(y0-1000*(a)) )\n",
        "      cv.line(img, pt1, pt2, (255, 0, 0), 2, cv.LINE_AA)\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hough transform slike crossword.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Zadatak 3\n",
        "\n",
        "Isprobajte isti kod od gore, ali postavite vrijednost parametra `theta` na `math.pi/180`. Primjetite razliku u tome koje su linije detektirane."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>5.3. Corner Detection</h4>\n",
        "\n",
        "Corners are locations in images where a slight shift in the location will lead to a large change in intensity in both horizontal and vertical axes.\n",
        "The Harris Corner detection algorithm consist of following steps:\n",
        "\n",
        "<ul>\n",
        "<li><b>Determination of windows (small image patches) with large intensity variation</b></li>\n",
        "\n",
        "Let a window (the center) be located at position  &nbsp; ![cornerr](https://latex.codecogs.com/gif.latex?%28x%2Cy%29).  &nbsp; \n",
        "Let the intensity of the pixel at this location be  &nbsp; ![cornerrr](https://latex.codecogs.com/gif.latex?I%28x%2Cy%29).  &nbsp;\n",
        "If this window slightly shifts to a new location with displacement  &nbsp; ![corner7](https://latex.codecogs.com/gif.latex?%28u%2Cv%29),  &nbsp; the intensity of the pixel at this location will be \n",
        " &nbsp; ![corner8](https://latex.codecogs.com/gif.latex?I%28x&plus;u%2Cy&plus;v%29).  &nbsp; \n",
        "\n",
        "Therefore,  &nbsp; ![corner9](https://latex.codecogs.com/gif.latex?%5BI%28x&plus;u%2Cy&plus;v%29-I%28x%2Cy%29%5D)  &nbsp; will be the difference in intensities of the window shift. \n",
        "For a corner, this difference will be very high. \n",
        "We maximize this term by differentiating it with respect to the X and Y axes. \n",
        "Let  &nbsp; ![corner10](https://latex.codecogs.com/gif.latex?w%28x%2Cy%29)  &nbsp;be the weights of pixels over a window (Rectangular or a Gaussian).\n",
        "Then,  &nbsp; ![corner11](https://latex.codecogs.com/gif.latex?E%28u%2Cv%29)  &nbsp; is defined as :\n",
        "<p align=\"center\">\n",
        "<img src=\"https://cdn-images-1.medium.com/max/800/0*v4pgxvEFE8JvroJv.png\" alt=\"hough1\" border=\"0\"></a><br /><br />\n",
        "</p>\n",
        "\n",
        "\n",
        "Since,computing &nbsp; ![corner11](https://latex.codecogs.com/gif.latex?E%28u%2Cv%29)  &nbsp; will be computationally challenged, optimisation with Taylor series expansion (only the 1rst order)\n",
        "is applyed. Some math leads us to: <br/>\n",
        "\n",
        "![corner12](https://latex.codecogs.com/gif.latex?E%28u%2Cv%29%5Capprox%20%28u%2Cv%29M%5Cbinom%7Bx%7D%7By%7D). &nbsp; \n",
        "\n",
        "And finally structure tensor is defined with :\n",
        "<p align=\"center\">\n",
        "&nbsp;<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/a617dda21e306dbfbdb7a186b1c203e3f3443867\" alt=\"hough1\" border=\"0\"></a><br /><br />\n",
        "</p>\n",
        "\n",
        "<li><b>Computation of score R for each found window</b></li>\n",
        "After fiding windows with large variations, selection of suitable corners is performed. \n",
        "It was estimated that the eigenvalues of the matrix can be used to do this. Calculation of a score associated with each such window is given with:  <br/>\n",
        "\n",
        "![corner2](https://latex.codecogs.com/gif.latex?R%20%3D%20det%28M%29%20-%20k%5Ccdot%20%28trace%28M%29%29%5E%7B2%7D)   <br/>\n",
        "\n",
        "where &nbsp; ![corner2](https://latex.codecogs.com/gif.latex?det%28M%29%20%3D%20%5Clambda%20_%7B1%7D%20%5Ccdot%20%5Clambda_%7B2%7D) &nbsp; and &nbsp; \n",
        "&nbsp; ![corner3](https://latex.codecogs.com/gif.latex?trace%28M%29%20%3D%20%5Clambda%20_%7B1%7D%20&plus;%20%5Clambda_%7B2%7D).  &nbsp;\n",
        "Here,  &nbsp; ![corner4](https://latex.codecogs.com/gif.latex?%5Clambda%20_%7B1%7D) &nbsp; and  &nbsp; ![corner5](https://latex.codecogs.com/gif.latex?%5Clambda%20_%7B2%7D)  &nbsp; \n",
        "are eigenvalues of M, and k is an empirical constant. \n",
        "\n",
        "\n",
        "<li><b>Applying a threshold to the score R and important corners selection</b></li>\n",
        "\n",
        "Depending on the value of R, the window is classified as consisting of flat, edge, or a corner. \n",
        "A large value of R indicates a corner, a negative value indicates an edge. \n",
        "Also, in order to pick up the optimal values to indicate corners, we find the local maxima as corners within the window which is a 3 by 3 filter.\n",
        "\n",
        "</ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OpenCV implementation of Harris Corner detector can be found in: \n",
        "\n",
        "```\n",
        "Function : cv2.cornerHarris(image,blocksize,ksize,k)\n",
        "Parameters are as follows :\n",
        "1. image : the source image in which we wish to find the corners (grayscale)\n",
        "2. blocksize : size of the neighborhood in which we compare the gradient \n",
        "3. ksize : aperture parameter for the Sobel() Operator (used for finding Ix and Iy)\n",
        "4. k : Harris detector empirical constant parameter (used in the calculation of R)\n",
        "```\n",
        "More information can be found at:  <a href=\"https://docs.opencv.org/3.0-beta/modules/imgproc/doc/feature_detection.html?highlight=cv2.cornerharris#cv2.cornerHarris\">OpenCV cv2.cornerHarris documentation</a> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Zadatak 4\n",
        "\n",
        "Na slici `slike/crossword.jpg` obavite corner detection tako da se vide kutovi križaljke. Učitajte sliku kao **grayscale** s njom pozovite `cornerHarris` funkciju. Primjer poziva s dobrim početnim vrijednostima parametara:\n",
        "\n",
        "`corners = cv.cornerHarris(img, 15, 3, 0.05)`\n",
        "\n",
        "Zatim izvornu sliku postavite na 255 svuda gdje je `corners` slika veća od određene vrijednosti. Imajte na umu da će `corners` slika sadržavati vrlo male vrijednosti, tako da dobar početni threshold je reda veličine 0.0001. Prisjetite se prvih labosa za thresholdanje slike, odnosno postavljanja vrijednosti slike gdje je druga slika veća od neke vrijednosti. Prikažite rezultirajuču sliku. Probajte modificirati parametre `blocksize`, `k` ili threshold da što bolje prikažete kutove križaljke."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Kombinacijom Canny edge detektora i Harris corner detektora možemo segmentirati različite dijelove slika. Npr. možemo brojati krvne stanice na mikroskopskim slikama, pronači rješenja sudokua, križaljki ili u šahu, detektirati pukotine i anomalije u raznim materijalima ili cestama i sl."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ne zaboravite spremiti zadatke na GitHub!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPdsk5aJ45he4xMUxx8bkpd",
      "include_colab_link": true,
      "name": "lab1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
